{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\""
      ],
      "metadata": {
        "id": "CbEz5UOAxWYO"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pip uninstall clearml\n",
        "%pip uninstall wandb"
      ],
      "metadata": {
        "id": "od43Tqqaw7LB",
        "outputId": "8de9a3ac-0d8d-4903-dd10-59b5d99cdc4f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping clearml as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping wandb as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['WANDB_DISABLED'] = 'true'"
      ],
      "metadata": {
        "id": "w5OBfYswxzx4"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-FSuXqDmZpW",
        "outputId": "7ad2c88a-6953-4283-c323-d413853aaaf6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running in Colab\n",
            "\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0K\u001b[36m> destination directory is not empty. Using --force, continuing\u001b[39m\n",
            "\u001b[36m> cloned \u001b[1mxldrkp/autodistill-example\u001b[22m#\u001b[1mHEAD\u001b[22m\u001b[39m\n",
            "\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0K"
          ]
        }
      ],
      "source": [
        "# Import from GitHub in Colab\n",
        "\n",
        "if os.getenv(\"COLAB_RELEASE_TAG\"):\n",
        "   print(\"Running in Colab\")\n",
        "   !npx degit xldrkp/autodistill-example -f"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T9u9JdqFe1ZJ"
      },
      "outputs": [],
      "source": [
        "%pip install autodistill autodistill-grounded-sam autodistill-yolov8 roboflow scikit-learn autodistill-grounding-dino ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "iUTuL-9fftWg",
        "outputId": "17b43ef0-6a81-44de-f706-fc0dbf5df4eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trying to load grounding dino directly\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3595.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "final text_encoder_type: bert-base-uncased\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n"
          ]
        }
      ],
      "source": [
        "from autodistill_grounded_sam import GroundedSAM\n",
        "from autodistill_grounding_dino import GroundingDINO\n",
        "from autodistill.detection import CaptionOntology\n",
        "from autodistill_yolov8 import YOLOv8\n",
        "\n",
        "base_model = GroundingDINO(ontology=CaptionOntology(\n",
        "    {\n",
        "        \"clothes pin\": \"OK\",\n",
        "        \"broken clothes pin with torsion spiral\": \"NOK_spiral\",\n",
        "        \"broken clothes pin without torsion spiral\": \"NOK_nospiral\"\n",
        "    }\n",
        "))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PFqXfvzdhonF"
      },
      "outputs": [],
      "source": [
        "base_model.label(\n",
        "    input_folder=\"./images\",\n",
        "    extension=\".jpg\",\n",
        "    output_folder=\"./labeled-images\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nTfGJxiDQYWc",
        "outputId": "0cbde494-1d77-4a43-fe03-c3ca9f7ecdba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "New https://pypi.org/project/ultralytics/8.3.63 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
            "Ultralytics YOLOv8.0.81 ðŸš€ Python-3.11.11 torch-2.5.1+cu121 CPU\n",
            "\u001b[34m\u001b[1myolo/engine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=./labeled-images/data.yaml, epochs=200, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=cpu, workers=8, project=None, name=None, exist_ok=False, pretrained=False, optimizer=SGD, verbose=True, seed=0, deterministic=True, single_cls=False, image_weights=False, rect=False, cos_lr=False, close_mosaic=0, resume=False, amp=True, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, line_thickness=3, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, v5loader=False, tracker=botsort.yaml, save_dir=runs/detect/train4\n",
            "Overriding model.yaml nc=80 with nc=3\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.Conv                  [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.Conv                  [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.C2f                   [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.Conv                  [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.C2f                   [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.Conv                  [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.C2f                   [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.Conv                  [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.C2f                   [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.SPPF                  [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.C2f                   [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.C2f                   [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.Conv                  [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.C2f                   [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.Conv                  [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.C2f                   [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    751897  ultralytics.nn.modules.Detect                [3, [64, 128, 256]]           \n",
            "Model summary: 225 layers, 3011433 parameters, 3011417 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train4', view at http://localhost:6006/\n",
            "`torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/labeled-images/train/labels... 445 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 445/445 [00:01<00:00, 335.59it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/labeled-images/train/labels.cache\n",
            "A new version of Albumentations is available: 2.0.0 (you have 1.4.20). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
            "Got processor for bboxes, but no transform to process it.\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/labeled-images/valid/labels... 112 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 112/112 [00:00<00:00, 386.28it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/labeled-images/valid/labels.cache\n",
            "Plotting labels to runs/detect/train4/labels.jpg... \n",
            "Image sizes 640 train, 640 val\n",
            "Using 0 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train4\u001b[0m\n",
            "Starting training for 200 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "  0%|          | 0/28 [00:00<?, ?it/s]`torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      1/200     0.736G     0.8151      2.956      1.214         96        640:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 20/28 [03:50<01:30, 11.36s/it]"
          ]
        }
      ],
      "source": [
        "target_model = YOLOv8(\"yolov8n.pt\")\n",
        "target_model.train(\"./labeled-images/data.yaml\", epochs=200)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}